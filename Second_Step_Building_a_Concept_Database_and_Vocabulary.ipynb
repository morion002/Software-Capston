{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4bQfWfXlKWJ"
   },
   "source": [
    "### First we need to install MedCAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlMQ2iQrlG69",
    "outputId": "c8c3a2cd-9a8a-45e9-9041-1644368b6234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting medcat==0.3.3.1\n",
      "  Downloading medcat-0.3.3.1-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 2.7 MB/s \n",
      "\u001b[?25hCollecting tokenizers~=0.6.0\n",
      "  Downloading tokenizers-0.6.0-cp37-cp37m-manylinux1_x86_64.whl (5.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.7 MB 11.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas~=1.0 in /usr/local/lib/python3.7/dist-packages (from medcat==0.3.3.1) (1.3.5)\n",
      "Requirement already satisfied: scipy~=1.4 in /usr/local/lib/python3.7/dist-packages (from medcat==0.3.3.1) (1.4.1)\n",
      "Collecting torch~=1.4.0\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 6.7 kB/s \n",
      "\u001b[?25hCollecting gensim~=3.7\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 81.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Flask~=1.1 in /usr/local/lib/python3.7/dist-packages (from medcat==0.3.3.1) (1.1.4)\n",
      "Requirement already satisfied: numpy~=1.18 in /usr/local/lib/python3.7/dist-packages (from medcat==0.3.3.1) (1.21.6)\n",
      "Requirement already satisfied: spacy==2.2.4 in /usr/local/lib/python3.7/dist-packages (from medcat==0.3.3.1) (2.2.4)\n",
      "Collecting torchvision~=0.5.0\n",
      "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 41.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (57.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (1.0.7)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (7.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (2.23.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (3.0.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (4.64.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (0.9.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.4->medcat==0.3.3.1) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.2.4->medcat==0.3.3.1) (4.11.3)\n",
      "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1->medcat==0.3.3.1) (1.0.1)\n",
      "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1->medcat==0.3.3.1) (1.1.0)\n",
      "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1->medcat==0.3.3.1) (7.1.2)\n",
      "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask~=1.1->medcat==0.3.3.1) (2.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim~=3.7->medcat==0.3.3.1) (6.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim~=3.7->medcat==0.3.3.1) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4->medcat==0.3.3.1) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.2.4->medcat==0.3.3.1) (3.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask~=1.1->medcat==0.3.3.1) (2.0.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.0->medcat==0.3.3.1) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas~=1.0->medcat==0.3.3.1) (2.8.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->medcat==0.3.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->medcat==0.3.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->medcat==0.3.3.1) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.4->medcat==0.3.3.1) (1.24.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.5.0->medcat==0.3.3.1) (7.1.2)\n",
      "Installing collected packages: torch, torchvision, tokenizers, gensim, medcat\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0+cu113\n",
      "    Uninstalling torch-1.11.0+cu113:\n",
      "      Successfully uninstalled torch-1.11.0+cu113\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0+cu113\n",
      "    Uninstalling torchvision-0.12.0+cu113:\n",
      "      Successfully uninstalled torchvision-0.12.0+cu113\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\n",
      "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed gensim-3.8.3 medcat-0.3.3.1 tokenizers-0.6.0 torch-1.4.0 torchvision-0.5.0\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_md-0.2.4.tar.gz\n",
      "  Downloading https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_md-0.2.4.tar.gz (70.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 70.0 MB 48 kB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from en-core-sci-md==0.2.4) (2.2.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (1.1.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (2.0.6)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (7.4.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (4.64.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (1.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (57.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (1.21.6)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.1->en-core-sci-md==0.2.4) (0.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en-core-sci-md==0.2.4) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en-core-sci-md==0.2.4) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.1->en-core-sci-md==0.2.4) (4.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-md==0.2.4) (2022.5.18.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-md==0.2.4) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-md==0.2.4) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.1->en-core-sci-md==0.2.4) (2.10)\n",
      "Building wheels for collected packages: en-core-sci-md\n",
      "  Building wheel for en-core-sci-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-sci-md: filename=en_core_sci_md-0.2.4-py3-none-any.whl size=70498245 sha256=d76d296cb7d31e28ee15fafb73768cb3623a270d6f49c82fff00817a4c914304\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/e4/01/703c1762f2ea429f1ca52703c83eeac63a668f043d92e0333f\n",
      "Successfully built en-core-sci-md\n",
      "Installing collected packages: en-core-sci-md\n",
      "Successfully installed en-core-sci-md-0.2.4\n"
     ]
    }
   ],
   "source": [
    "! pip install medcat==0.3.3.1\n",
    "# Get the scispacy model\n",
    "! pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_md-0.2.4.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWScf8BW0BpY"
   },
   "source": [
    "**Restart the runtime if on colab, sometimes necessary after installing models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KByaUPYNk7gk",
    "outputId": "b7426165-483e-4e65-b30a-f2188811e90b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing the missing models for scispacy\n",
      "\n",
      "Installing the missing models for scispacy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from medcat.cat import CAT\n",
    "from medcat.cdb import CDB\n",
    "from medcat.utils.vocab import Vocab\n",
    "from medcat.prepare_cdb import PrepareCDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKgZTiZxk7gp"
   },
   "outputs": [],
   "source": [
    "!mkdir -p data\n",
    "DATA_DIR = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IRLcv4dGIEbS",
    "outputId": "f06f0344-1201-406c-e4ad-d46004529447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-26 04:40:20--  https://raw.githubusercontent.com/CogStack/MedCAT/master/tutorial/data/cdb_simple.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2022-05-26 04:40:20 ERROR 404: Not Found.\n",
      "\n",
      "--2022-05-26 04:40:20--  https://raw.githubusercontent.com/CogStack/MedCAT/master/tutorial/data/cdb_advanced.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2022-05-26 04:40:20 ERROR 404: Not Found.\n",
      "\n",
      "--2022-05-26 04:40:20--  https://raw.githubusercontent.com/CogStack/MedCAT/master/tutorial/data/vocab_data.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 404 Not Found\n",
      "2022-05-26 04:40:20 ERROR 404: Not Found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/CogStack/MedCAT/master/tutorial/data/cdb_simple.csv -P ./data/\n",
    "!wget https://raw.githubusercontent.com/CogStack/MedCAT/master/tutorial/data/cdb_advanced.csv -P ./data/\n",
    "!wget https://raw.githubusercontent.com/CogStack/MedCAT/master/tutorial/data/vocab_data.txt -P ./data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9POZ_dwsk7gu"
   },
   "source": [
    "# Building a Vocabulary\n",
    "\n",
    "The first of the two required models when running MedCAT is a Vocabulary model (Vocab). The model is used for two things: (1) Spell checking; and (2) Word Embedding. \n",
    "\n",
    "The Vocab is very simple and you can easily build it from a file that is structured as below:\n",
    "```\n",
    "<token>\\t<word_count>\\t<vector_embedding_separated_by_spaces>\n",
    "```\n",
    "`token` - Usually a word or subword if you are using Byte Pair Encoding or something similar.\n",
    "\n",
    "`word_count` - The count for this word in your dataset or in any large dataset (wikipedia also works nicely).\n",
    "\n",
    "`vector_embedding_separated_by_spaces` - precalculated vector embedding, can be from Word2Vec or BERT or Whatever\n",
    "\n",
    "---\n",
    "An example with 3-dim embedding would be:\n",
    "```\n",
    "house\t34444\t 0.3232 0.123213 1.231231\n",
    "dog\t14444\t0.76762 0.76767 1.45454\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "The file is basically a TSV, but should not have any heading. \n",
    "\n",
    "---\n",
    "\n",
    "**NOTE**: If spelling is important for your use-case, take care that there are no misspelled words in the Vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "l_LAff3tMbeu",
    "outputId": "b3081b20-47b9-493b-b22a-a4d0ab4307a4"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d155206425d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmedcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the new Vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/medcat/utils/vocab.py\u001b[0m in \u001b[0;36madd_words\u001b[0;34m(self, path, replace)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mexisting\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreplaced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "from medcat.utils.vocab import Vocab\n",
    "vocab = Vocab()\n",
    "vocab.add_words(path = \"\")\n",
    "# Save the new Vocab\n",
    "vocab.save_dict(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "OgMSGHyhk7gv",
    "outputId": "991ffadb-c7f6-479b-f3c0-a8dbc31d9d8d"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-33457d8c23cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/medcat/utils/vocab.py\u001b[0m in \u001b[0;36madd_words\u001b[0;34m(self, path, replace)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mexisting\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mreplaced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/vocab_data.txt'"
     ]
    }
   ],
   "source": [
    "# Let's have a look at an example, I've created a small vocabulary with only 2 words (the ones from above)\n",
    "#and saved them into a text file. Let's try to create a vocabulary from this two words.\n",
    "file_path = DATA_DIR + \"vocab_data.txt\"\n",
    "\n",
    "vocab = Vocab()\n",
    "vocab.add_words(path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPl6ghXUk7gy"
   },
   "source": [
    "**And that is everything, with this we have built our vocab and no futher training is necessary.**\n",
    "\n",
    "---\n",
    "\n",
    "A couple of useful functions of the vocab are presented below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "HeVMPs5Zk7gy",
    "outputId": "53bb04b6-b4f7-4220-d4ac-b55261c557f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['house', 'dog'])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the words in the vocab\n",
    "vocab.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "SclVqlDgk7g2",
    "outputId": "3504bf87-f0cd-457d-8881-c033ab3d1074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['house', 'dog', 'test'])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to add words manually (one by one) use:\n",
    "vocab.add_word(\"test\", cnt=31, vec=[1.42, 1.44, 1.55], replace=True)\n",
    "vocab.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JnCgpKrEk7g5",
    "outputId": "1358a3a9-7f4d-42a2-c318-8972488a4794"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3232  , 0.123213, 1.231231])"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a vector of word use:\n",
    "vocab.vec(\"house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bO4IEvrJk7g8",
    "outputId": "aa2d40c6-a28a-4c41-de9a-d288509559ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34444"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or to get the count\n",
    "vocab['house']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fLg63Z9Yk7g-",
    "outputId": "0937dcce-3d3a-4680-be72-ab35883d5bcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To chec is a word in the vocab:\n",
    "\"house\" in vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG3FCinSl_Sq"
   },
   "source": [
    "### Before we save the vocab model, we need to create the unigram table for negative sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdC8eennmSM4"
   },
   "outputs": [],
   "source": [
    "# This is necessary after each change of the vocabulary (when we add new words)\n",
    "vocab.make_unigram_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6itJcEXk7hA"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgRtW7eqk7hB"
   },
   "outputs": [],
   "source": [
    "vocab.save_dict(DATA_DIR + \"vocab.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YBbwcNUk7hD"
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_tOsE6ak7hE"
   },
   "outputs": [],
   "source": [
    "vocab = Vocab()\n",
    "vocab.load_dict(DATA_DIR + \"vocab.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptRmHln9k7hG"
   },
   "source": [
    "# Building the Concept Database (CDB)\n",
    "\n",
    "The second model we are going to need when using MedCAT is the ConceptDB (CDB). This database holds a list of all concepts that we would like to detect and link to. For a lot of medical use-cases we would use giant databases like the UMLS or SNOMED. But, MedCAT can be used with any database no matter how big/small it is. \n",
    "\n",
    "To prepare the CDB we start off with a CSV with the following structure:\n",
    "```\n",
    "cui,str\n",
    "1,kidney failure\n",
    "7,CoVid 2\n",
    "7,coronavirus\n",
    "```\n",
    "This is the most basic version of the CSV file, it has only:\n",
    "\n",
    "`cui` - The concept unique identifier, this is simply an `ID` in your database\n",
    "\n",
    "`str` - String/Name of that concept. It is important to write all possible names and abbreviations for a concept of interest.\n",
    "\n",
    "If you have once concept that has multiple different names (like the one above with cui=7), you can simply add multiple rows with the same concept ID and MedCAT will merge that during the build phase.\n",
    "\n",
    "## The Full CSV Specification\n",
    "```\n",
    "cui,str,onto,tty,tui,sty,desc,is_unique,examples\n",
    "1,Kidney Failure|failure of kidneys|KF,SNOMED,PM,T047,Disease,Description of the concept,The patient was diagnosed with kidney failure\n",
    ".\n",
    ".\n",
    ".\n",
    "```\n",
    "This fileds are optional, anyone can be included or left out in your CSV.\n",
    "\n",
    "`onto` - Source ontology, e.g. HPO, SNOMED, HPC,...\n",
    "\n",
    "`tty` - Term type e.g. PN - Primary Name. Primary names are important and I would always recommend to add this fields when creating your CDB. \n",
    "\n",
    "`tui` - Semantic type identifier - e.g. T047 (taken from UMLS). A list of all semantic types can be found [here](https://metamap.nlm.nih.gov/Docs/SemanticTypes_2018AB.txt). \n",
    "\n",
    "`sty` - Semantic type - e.g. Disease\n",
    "\n",
    "`desc` - Description of this concept\n",
    "\n",
    "`examples` - Examples of this concept in a sentence (use short examples, not whole documents).\n",
    "\n",
    "\n",
    "***Note***: If one concept has multiple names, you can also separate the different names by a \"|\" - pipe - symbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "op5-LDOfk7hH",
    "outputId": "db3d8410-8e2c-4727-d22c-028302a26a9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n"
     ]
    }
   ],
   "source": [
    "# Let's try building the concept databse from a simple CSV\n",
    "prep_cdb = PrepareCDB(vocab=vocab)\n",
    "\n",
    "# Crete an array for paths to CSV files that will be used to build our CDB\n",
    "paths = [DATA_DIR + 'cdb_simple.csv']\n",
    "cdb = prep_cdb.prepare_csvs(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Q0FmKZQ2wzkS",
    "outputId": "927d794a-f12b-4879-c620-0c9ce4354b0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'site' from '/usr/lib/python3.6/site.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import site\n",
    "from importlib import reload\n",
    "reload(site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "lwlOBilek7hJ",
    "outputId": "f62adc46-6d22-4649-d2f4-bdd8d6b61ef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'kidney failure'}, '7': {'coronavirus', 'CoVid 2'}}\n"
     ]
    }
   ],
   "source": [
    "print(cdb.cui2original_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "qbO3dsLpk7hL",
    "outputId": "4ab4ace4-fb57-42cf-f646-7b0d5f74055d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n"
     ]
    }
   ],
   "source": [
    "prep_cdb = PrepareCDB(vocab=vocab)\n",
    "\n",
    "# To build fromm the advanced CSV example\n",
    "paths = [DATA_DIR + 'cdb_advanced.csv']\n",
    "cdb = prep_cdb.prepare_csvs(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08agsFBnk7hQ"
   },
   "source": [
    "**That is all, nothing else is necessary to build the CDB**\n",
    "\n",
    "---\n",
    "\n",
    "Some useful functions of the cdb are below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "uD3AYqqkk7hQ",
    "outputId": "7900ba85-9c43-4456-8e00-d7df23cacb4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'kidney failure'}, '7': {'coronavirus', 'CoVid 2'}}\n"
     ]
    }
   ],
   "source": [
    "# To display all cuis and names in the db - note that MedCAT merged the names\n",
    "print(cdb.cui2original_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XYROG_l_k7hT",
    "outputId": "bd7a08cf-e595-4b05-b0a6-faf8ed5447a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T047': {'1'}}\n"
     ]
    }
   ],
   "source": [
    "# We have a link from tui to cui\n",
    "print(cdb.tui2cuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "j18tyQ2Kk7hV",
    "outputId": "56075959-5395-4277-b9c7-27729a703794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'T047'}\n"
     ]
    }
   ],
   "source": [
    "# Or vice versa - from cui to tui\n",
    "print(cdb.cui2tui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "1xxBjfndk7hX",
    "outputId": "ff763518-99e5-4b70-8ab7-27b82a808684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'Description of the concept\\n\\nnan'}\n"
     ]
    }
   ],
   "source": [
    "# Description is also there\n",
    "print(cdb.cui2desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lpx7zGvwk7ha"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fC01maOzk7ha"
   },
   "outputs": [],
   "source": [
    "cdb.save_dict(DATA_DIR + \"cdb.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97uiDwvAk7hc"
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J9Ft8PbFk7hc"
   },
   "outputs": [],
   "source": [
    "cdb = CDB()\n",
    "cdb.load_dict(DATA_DIR + \"cdb.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fwiKys4k7he"
   },
   "source": [
    "# End\n",
    "\n",
    "This is everything you need to create your own MedCAT models. In the next notebook you will see how to train and use these models to annotate documents. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.1 MedCAT Tutorial | Part 3.1 Building a Concept Database and Vocabulary.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
